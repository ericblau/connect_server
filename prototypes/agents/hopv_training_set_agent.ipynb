{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Agent prototype: Create ML training set from HOPV\n",
    "Check if training data is labelled in hopv records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import transfer_auth\n",
    "import search_client\n",
    "from globus_sdk import TransferData, GlobusError\n",
    "from gmeta_utils import gmeta_pop, format_gmeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "s_client = search_client.SearchClient(\"https://search.api.globus.org/\", \"mdf\")\n",
    "transfer_client = transfer_auth.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dataset_name = \"hopv\"\n",
    "local_ep = \"0bc1cb98-d2af-11e6-9cb1-22000a1e3b52\"\n",
    "dest_ep = \"82f1b5c6-6e9b-11e5-ba47-22000b92c6ec\"\n",
    "dest_path = \"/sample_data/\"+dataset_name+\"_train.csv\"\n",
    "timeout = False\n",
    "timeout_intervals = 10\n",
    "interval_time = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if not local_ep:\n",
    "    pgr_res = transfer_client.endpoint_search(filter_scope=\"my-endpoints\")\n",
    "    ep_candidates = pgr_res.data\n",
    "    if len(ep_candidates) < 1: #Nothing found\n",
    "        raise GlobusError(\"Error: No local endpoints found\")\n",
    "    elif len(ep_candidates) == 1: #Exactly one candidate\n",
    "        if ep_candidates[0][\"gcp_connected\"] == False: #Is GCP, is not on\n",
    "            raise GlobusError(\"Error: Globus Connect is not running\")\n",
    "        else: #Is GCServer or GCP and connected\n",
    "            local_ep = ep_candidates[0][\"id\"]\n",
    "    else: # >1 found\n",
    "        #Filter out disconnected GCP\n",
    "        ep_connections = [candidate for candidate in ep_candidates if candidate[\"gcp_connected\"] is not False]\n",
    "        #Recheck list\n",
    "        if len(ep_connections) < 1: #Nothing found\n",
    "            raise GlobusError(\"Error: No local endpoints running\")\n",
    "        elif len(ep_connections) == 1: #Exactly one candidate\n",
    "            if ep_connections[0][\"gcp_connected\"] == False: #Is GCP, is not on\n",
    "                raise GlobusError(\"Error: Globus Connect is not active\")\n",
    "            else: #Is GCServer or GCP and connected\n",
    "                local_ep = ep_connections[0][\"id\"]\n",
    "        else: # >1 found\n",
    "            #Prompt user\n",
    "            print(\"Multiple endpoints found:\")\n",
    "            count = 0\n",
    "            for ep in ep_connections:\n",
    "                count += 1\n",
    "                print(count, \": \", ep[\"display_name\"], \"\\t\", ep[\"id\"])\n",
    "            print(\"\\nPlease choose the endpoint on this machine\")\n",
    "            ep_num = 0\n",
    "            while ep_num == 0:\n",
    "                usr_choice = input(\"Enter the number of the correct endpoint (-1 to cancel): \")\n",
    "                try:\n",
    "                    ep_choice = int(usr_choice)\n",
    "                    if ep_choice == -1: #User wants to quit\n",
    "                        ep_num = -1 #Will break out of while to exit program\n",
    "                    elif ep_choice in range(1, count+1): #Valid selection\n",
    "                        ep_num = ep_choice #Break out of while, return valid ID\n",
    "                    else: #Invalid number\n",
    "                        print(\"Invalid selection\")\n",
    "                except:\n",
    "                    print(\"Invalid input\")\n",
    "\n",
    "            if ep_num == -1:\n",
    "                print(\"Cancelling\")\n",
    "                sys.exit()\n",
    "            local_ep = ep_connections[ep_num-1][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fetch and aggregate records into training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hopv.experimental_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-852acb622e41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msearch_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmeta_pop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch_res\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hopv.experimental_data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hopv.experimental_data'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "num_processed = 0\n",
    "data_list = []\n",
    "while True:\n",
    "    query = {\n",
    "        \"q\": (\"mdf.source_name:\"+dataset_name+\" AND mdf.resource_type:record AND \"\n",
    "        \"mdf.scroll_id:(>=\" + str(count) + \" AND <\" + str(count + 10000) + \")\"),\n",
    "        \"advanced\": True,\n",
    "        \"limit\": 10000\n",
    "    }\n",
    "    raw_res = s_client.structured_search(query)\n",
    "    search_res = gmeta_pop(raw_res)\n",
    "    for res in search_res:\n",
    "        data_dict = json.loads(res[\"hopv.experimental_data\"])\n",
    "        data_list.append(data_dict)\n",
    "    num_ret = len(search_res)\n",
    "    if num_ret:\n",
    "        num_processed += num_ret\n",
    "        count += 10000\n",
    "    else:\n",
    "        break\n",
    "print(\"Processed:\", len(data_list), \"/\", num_processed, \"|\", len(data_list) - num_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)\n",
    "df.to_csv(os.path.join(os.getcwd(), \"temp_train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Upload to NCSA endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tdata = TransferData(transfer_client, local_ep, dest_ep, verify_checksum=True, notify_on_succeeded=False, notify_on_failed=False, notify_on_inactive=False)\n",
    "    tdata.add_item(os.path.join(os.getcwd(), \"temp_train.csv\"), dest_path)\n",
    "    res = transfer_client.submit_transfer(tdata)\n",
    "    if res[\"code\"] != \"Accepted\":\n",
    "        raise GlobusError(\"Failed to transfer files: Transfer \" + res[\"code\"])\n",
    "    else:\n",
    "        intervals = 0\n",
    "        while not transfer_client.task_wait(res[\"task_id\"], timeout=interval_time, polling_interval=interval_time):\n",
    "            for event in transfer_client.task_event_list(res[\"task_id\"]):\n",
    "                if event[\"is_error\"]:\n",
    "                    transfer_client.cancel_task(res[\"task_id\"])\n",
    "                    raise GlobusError(\"Error: \" + event[\"description\"])\n",
    "                if timeout and intervals >= timeout_intervals:\n",
    "                    transfer_client.cancel_task(res[\"task_id\"])\n",
    "                    raise GlobusError(\"Transfer timed out.\")\n",
    "                intervals += 1\n",
    "except Exception as e:\n",
    "    raise\n",
    "finally:\n",
    "    os.remove(os.path.join(os.getcwd(), \"temp_train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Update dataset entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"q\": \"mdf-source_name:\"+dataset_name+\" AND mdf-node_type:dataset\",\n",
    "    \"advanced\": True\n",
    "}\n",
    "raw_res = s_client.structured_search(query)\n",
    "search_res = gmeta_pop(raw_res)\n",
    "if len(search_res) != 1:\n",
    "    raise ValueError(\"Incorrect number of results: \" + str(len(search_res)))\n",
    "ingest = search_res[0]\n",
    "ingest[\"globus_subject\"] = raw_res[\"gmeta\"][0][\"subject\"]\n",
    "ingest[\"acl\"] = [\"public\"]\n",
    "ingest[\"mdf-links\"][\"training_set\"] = {\n",
    "    \"globus_endpoint\": dest_ep,\n",
    "    \"path\": dest_path,\n",
    "    \"http_host\": \"https://data.materialsdatafacility.org\" + dest_path\n",
    "}\n",
    "gmeta = format_gmeta([format_gmeta(ingest)])\n",
    "\n",
    "#gmeta = json.loads(json.dumps(gmeta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlobusHTTPResponse({'success': True})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_client.ingest(gmeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"q\": \"mdf-source_name:\"+dataset_name+\" AND mdf-node_type:dataset\",\n",
    "    \"advanced\": True\n",
    "}\n",
    "raw_res = s_client.structured_search(query)\n",
    "search_res = gmeta_pop(raw_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification:\n",
      " {\n",
      "    \"endpoint\": \"82f1b5c6-6e9b-11e5-ba47-22000b92c6ec\",\n",
      "    \"https\": \"https://data.materialsdatafacility.org/sample_data/hopv_train.csv\",\n",
      "    \"path\": \"/sample_data/hopv_train.csv\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"Verification:\\n\", json.dumps(search_res[0][\"mdf-links\"][\"training_set\"], sort_keys=True, indent=4, separators=(',', ': ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
